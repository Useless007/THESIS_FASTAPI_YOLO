import sys
import json
import cv2
import numpy as np
import torch
from ultralytics import YOLOv10 as YOLO
import os
import time
import base64
import threading
import queue

MODEL_PATH = "./app/models/best.pt"
model = None
model_lock = threading.Lock()

# ‡∏Ñ‡∏¥‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
frame_queue = queue.Queue(maxsize=5)  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ç‡∏ô‡∏≤‡∏î‡∏Ñ‡∏¥‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 5 ‡πÄ‡∏ü‡∏£‡∏°
result_queue = queue.Queue()

# ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
processing = False
processing_lock = threading.Lock()

def get_model():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO ‡∏ï‡∏≤‡∏° lazy loading pattern"""
    global model
    with model_lock:
        if model is None:
            # Check if CUDA (GPU) is available
            device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
            print(f"üîç Loading YOLO model on device: {device}")
            model = YOLO(MODEL_PATH)
    return model

def worker_thread():
    """
    Worker thread ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å thread ‡∏´‡∏•‡∏±‡∏Å
    ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Ñ‡∏¥‡∏ß‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏õ‡∏ó‡∏µ‡πà‡∏Ñ‡∏¥‡∏ß‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    """
    global processing
    try:
        with processing_lock:
            processing = True
        
        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÇ‡∏´‡∏•‡∏î
        yolo_model = get_model()
        
        # Check if CUDA (GPU) is available
        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
        
        while processing:
            try:
                # ‡∏£‡∏±‡∏ö‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Ñ‡∏¥‡∏ß‡πÇ‡∏î‡∏¢‡∏£‡∏≠‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                frame, rtsp_url, save_annotated = frame_queue.get(timeout=1.0)
                
                # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• YOLO
                results = yolo_model.predict(source=frame, conf=0.1, iou=0.45, stream=False, device=device)
                
                # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏≤‡∏î
                annotated_frame = frame.copy()
                
                detections = []
                for result in results:
                    for box in result.boxes.data:
                        x1, y1, x2, y2, conf, cls = box.tolist()
                        
                        if conf > 0.6:
                            # Get integer coordinates for drawing
                            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                            label = yolo_model.names[int(cls)]
                            
                            # Draw bounding box
                            cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            
                            # Add label with confidence score
                            text = f"{label}: {conf:.2f}"
                            font = cv2.FONT_HERSHEY_SIMPLEX
                            text_size = cv2.getTextSize(text, font, 0.5, 2)[0]
                            
                            # Background for text (for better visibility)
                            cv2.rectangle(annotated_frame, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), (0, 255, 0), -1)
                            
                            # Text
                            cv2.putText(annotated_frame, text, (x1, y1 - 5), font, 0.5, (0, 0, 0), 2)
                            
                            detections.append({
                                "label": label,
                                "confidence": float(conf),
                                "box": [float(x1), float(y1), float(x2), float(y2)],
                            })
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏õ‡πá‡∏ô base64
                _, raw_buffer = cv2.imencode('.jpg', frame)
                raw_base64 = base64.b64encode(raw_buffer).decode('utf-8')
                
                # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡πÄ‡∏õ‡πá‡∏ô base64
                _, annotated_buffer = cv2.imencode('.jpg', annotated_frame)
                annotated_base64 = base64.b64encode(annotated_buffer).decode('utf-8')
                
                # ‡∏•‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ CUDA
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                
                # Save the annotated frame if requested
                annotated_path = None
                if save_annotated:
                    temp_dir = "./uploads/temp_realtime"
                    os.makedirs(temp_dir, exist_ok=True)
                    timestamp = int(time.time() * 1000)
                    annotated_path = f"{temp_dir}/frame_{timestamp}.jpg"
                    cv2.imwrite(annotated_path, annotated_frame)
                
                # ‡πÉ‡∏™‡πà‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏•‡∏á‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                result_queue.put((detections, raw_base64, annotated_base64, annotated_path))
                
                # ‡πÅ‡∏à‡πâ‡∏á frame_queue ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
                frame_queue.task_done()
                
            except queue.Empty:
                # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏¥‡∏ß‡∏ß‡πà‡∏≤‡∏á ‡∏Å‡πá‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£
                continue
            except Exception as e:
                print(f"‚ùå Error in worker thread: {str(e)}")
                # ‡πÉ‡∏™‡πà‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î
                result_queue.put(([], "", "", None))
                # ‡πÅ‡∏à‡πâ‡∏á frame_queue ‡∏ß‡πà‡∏≤‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
                try:
                    frame_queue.task_done()
                except:
                    pass
    
    except Exception as e:
        print(f"‚ùå Fatal error in worker thread: {str(e)}")
    finally:
        with processing_lock:
            processing = False

def start_worker():
    """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á worker thread ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°"""
    global processing
    with processing_lock:
        if not processing:
            # ‡πÄ‡∏£‡∏¥‡πà‡∏° worker thread
            worker = threading.Thread(target=worker_thread, daemon=True)
            worker.start()
            return True
    return False

def stop_worker():
    """‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á worker thread"""
    global processing
    with processing_lock:
        processing = False
    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏¥‡∏ß‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤
    if not frame_queue.empty():
        try:
            frame_queue.join()
        except:
            pass

def process_rtsp(cam_ip, save_annotated=True):
    """
    Process RTSP stream from camera for real-time object detection
    
    Args:
        cam_ip (str): Camera IP address or RTSP URL
        save_annotated (bool): Whether to save annotated frames
        
    Returns:
        Generator that yields tuples (detections, raw_frame, annotated_frame)
    """
    # ‡πÄ‡∏£‡∏¥‡πà‡∏° worker thread ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏£‡∏¥‡πà‡∏°
    start_worker()
    
    # Open RTSP stream
    cap = cv2.VideoCapture(cam_ip)
    
    if not cap.isOpened():
        raise Exception(f"Failed to open RTSP stream at {cam_ip}")
    
    try:
        while True:
            ret, frame = cap.read()
            
            if not ret:
                print(f"‚ö†Ô∏è Failed to read frame from {cam_ip}")
                time.sleep(0.5)  # Pause briefly before retry
                continue
            
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏¥‡∏ß‡πÑ‡∏°‡πà‡πÄ‡∏ï‡πá‡∏° ‡πÉ‡∏´‡πâ‡πÉ‡∏™‡πà‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß
            try:
                if not frame_queue.full():
                    frame_queue.put((frame, cam_ip, save_annotated), block=False)
            except queue.Full:
                # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏¥‡∏ß‡πÄ‡∏ï‡πá‡∏° ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ‡πÄ‡∏ü‡∏£‡∏°‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
                pass
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            try:
                detections, raw_base64, annotated_base64, annotated_path = result_queue.get(block=False)
                result_queue.task_done()
                yield detections, raw_base64, annotated_base64, annotated_path
            except queue.Empty:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°‡πÄ‡∏õ‡∏•‡πà‡∏≤
                _, raw_buffer = cv2.imencode('.jpg', frame)
                raw_base64 = base64.b64encode(raw_buffer).decode('utf-8')
                yield [], raw_base64, raw_base64, None
            
            # ‡∏ô‡∏≠‡∏ô‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ CPU ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
            time.sleep(0.05)
    
    except Exception as e:
        print(f"‚ùå Error in RTSP processing: {str(e)}")
    finally:
        # Release resources
        cap.release()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print(json.dumps({"error": "No image path provided"}), file=sys.stderr)
        sys.exit(1)

    image_path = sys.argv[1]
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á model instance
        model = get_model()
        
        # ‡∏≠‡πà‡∏≤‡∏ô‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        frame = cv2.imread(image_path)
        if frame is None:
            raise ValueError(f"Failed to read image: {image_path}")
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• YOLO ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô worker thread
        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
        results = model.predict(source=frame, conf=0.1, iou=0.45, stream=False, device=device)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡πä‡∏≠‡∏õ‡∏õ‡∏µ‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏≤‡∏î
        annotated_frame = frame.copy()
        
        detections = []
        for result in results:
            for box in result.boxes.data:
                x1, y1, x2, y2, conf, cls = box.tolist()
                
                if conf > 0.3:
                    # Get integer coordinates for drawing
                    x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)
                    label = model.names[int(cls)]
                    
                    # Draw bounding box
                    cv2.rectangle(annotated_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                    
                    # Add label with confidence score
                    text = f"{label}: {conf:.2f}"
                    font = cv2.FONT_HERSHEY_SIMPLEX
                    text_size = cv2.getTextSize(text, font, 0.5, 2)[0]
                    
                    # Background for text (for better visibility)
                    cv2.rectangle(annotated_frame, (x1, y1 - text_size[1] - 10), (x1 + text_size[0], y1), (0, 255, 0), -1)
                    
                    # Text
                    cv2.putText(annotated_frame, text, (x1, y1 - 5), font, 0.5, (0, 0, 0), 2)
                    
                    detections.append({
                        "label": label,
                        "confidence": float(conf),
                        "box": [float(x1), float(y1), float(x2), float(y2)],
                    })
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÅ‡∏•‡πâ‡∏ß
        temp_dir = "./uploads/temp_realtime"
        os.makedirs(temp_dir, exist_ok=True)
        timestamp = int(time.time() * 1000)
        annotated_path = f"{temp_dir}/frame_{timestamp}.jpg"
        cv2.imwrite(annotated_path, annotated_frame)
        
        # Return both detections and path to annotated image
        sys.stdout.write(json.dumps({
            "detections": detections,
            "annotated_image": annotated_path
        }))
    except Exception as e:
        sys.stderr.write(json.dumps({"error": str(e)}))
        sys.exit(1)